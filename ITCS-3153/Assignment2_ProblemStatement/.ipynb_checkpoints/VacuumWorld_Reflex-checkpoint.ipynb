{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51956090",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Introduction to Artificial Intelligence - ITCS 3153 - Spring 2023\n",
    "\n",
    "# Assignment 2: Model-based Reflex Agents for the Vacuum World\n",
    "\n",
    "<hr/>\n",
    "\n",
    "Add the following information when before submitting the assignment.\n",
    "\n",
    "**Name:** James Kelly\n",
    "<br>\n",
    "**Charlotte ID:** 801070244\n",
    "<br>\n",
    "**UNCC Email:** jkelly81@uncc.edu\n",
    "<br>\n",
    "(If applicable) **List of Collaborators and further acknowledgements:**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68f22a",
   "metadata": {},
   "source": [
    "We will use the `ipythonblocks` package for visualization purposes. If executing the following cell, go back to `Prep Work 5-1: Python and Jupyter Intro' to install the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dafe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipythonblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3611961",
   "metadata": {},
   "source": [
    "## Problem 1: Creating a model-based reflex agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735168d9",
   "metadata": {},
   "source": [
    "In this problem, we define first an environment of clean and dirty squares on a grid. The grid is of width `nr_cols` and height `nr_rows`. Half of the $\\text{nr_cols}\\cdot \\text{nr_rows}$ tiles are then chosen to be 'Dirty' at random. <br> The list `locs` contains a list of the tile coordinates, and `status` is defined as a `dict` whose keys are the tile coordinates and values correspond to the cleanliness status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae342f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_rows = 5\n",
    "nr_cols = 4\n",
    "locs = [(i,j) for j in range(nr_rows) for i in range(nr_cols)]\n",
    "print(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "status = dict(zip(locs,random.choices(['Clean', 'Dirty'],k=len(locs))))\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b0a5",
   "metadata": {},
   "source": [
    "By choosing `random.seed(42)`, we fix the _random seed_ for reproducibility. (The seed number can later be changed to obtain environments with dirt at different location.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c01ee",
   "metadata": {},
   "source": [
    "Using the `VacuumEnvironment` class of `vacuumworld.py`, we define a vacuum world environment accordingly, and then visualize the enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vacuumworld import *\n",
    "vacuum_env = VacuumEnvironment(locs=locs,status=status,color={'Agent': (0,0,0), 'Dirt': (200, 0, 0)})\n",
    "print(\"State of the Environment: {}.\".format(vacuum_env.status))\n",
    "vacuum_env.reveal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058b004",
   "metadata": {},
   "source": [
    "In the above visualization, we have the origin in the _lower left corner_. You can interpret the visualization as follows:\n",
    " -  A _red_ square corresponds to a dirty tile,\n",
    " -  A _gray_ square corresponds to a clean tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dirty tile: \")\n",
    "vacuum_env.grid[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clean tile: \")\n",
    "vacuum_env.grid[2:4,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766769d",
   "metadata": {},
   "source": [
    "Note: In grid coordinates, one \"tile\" corresponds to a square or size (2x2). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daad91e",
   "metadata": {},
   "source": [
    "In the above environment, we have not added yet visualized vacuum agent itself. In the following cell, we add an agent at location `(0,0)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba05ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.add_thing(Agent(),location=(0,0))\n",
    "#vacuum_env.delete_thing(vacuum_env.agents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5ed44",
   "metadata": {},
   "source": [
    "Then we visualize the environment again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.reveal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175808ed",
   "metadata": {},
   "source": [
    "We see that a dirty tile with vacuum agent on it looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dirty tile with vacuum agent: \")\n",
    "vacuum_env.grid[0:2,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ab63c",
   "metadata": {},
   "source": [
    "We now remove the agent from the location `(0,0)` and add it at `(1,0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vacuum_env.agents):\n",
    "    vacuum_env.delete_thing(vacuum_env.agents[0])\n",
    "vacuum_env.add_thing(Agent(),location=(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.reveal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd8df6",
   "metadata": {},
   "source": [
    "We see that a clean tile with vaccum agent on it looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clean tile with vacuum agent: \")\n",
    "vacuum_env.grid[2:4,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96759890",
   "metadata": {},
   "source": [
    "Subseqeuently, we remove the agent again from the environment as it does not possess an agent program yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1133149",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vacuum_env.agents):\n",
    "    vacuum_env.delete_thing(vacuum_env.agents[0])\n",
    "vacuum_env.reveal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f3a36",
   "metadata": {},
   "source": [
    "### Task Description\n",
    "Please solve the following task.\n",
    "<br>\n",
    "<b>\n",
    "Design the agent program of a model-based reflex vacuum agent with the following properties:\n",
    "</b>\n",
    "\n",
    "   - **For a vacuum agent that starts in tile `(0,0)`, it cleans the environment entirely from dirt.**\n",
    "   - We assume that our task environment is **partially observable**: the percepts are of the same type as in the two-tile vacuum world problem discussed in class in the sense that for each location, the agent is able to record its current coordinates as well as the cleanliness status (`'Dirty'` or `'Clean'`).\n",
    "   - The internal state of the vacuum agent keeps track of the tiles already visited and their cleanliness. <br> **Design the program such that an already visited tile is _not_ visited again.**\n",
    "   - For each time step, this agent program **chooses between one of the following actions**:\n",
    "       - `'Suck'`: The vacuum agent cleans the tile. This changes its cleanliness status from `'Dirty'` to `'Clean'`. If the tile was already clean, nothing happens.\n",
    "       - `'NoOp'`: The vacuum agent does not do anything. Furthermore, the agent program terminates after this action is taken.\n",
    "       - `'Left'`: The vacuum agent moves from its current location to one tile on its left.\n",
    "       - `'Right'`: The vacuum agent moves from its current location to one tile on its right.\n",
    "       - `'Up'`: The vacuum\n",
    "       agent moves from its current location to one tile above it.\n",
    "       - `'Down'`: The vacuum agent moves from its current location to one tile below it. <br>\n",
    "       \n",
    "    If a location change is to result in \"bumping\" into the boundary of the vacuum world, the agent simply does not move.\n",
    "       - The agent shall not only be able to solve vacuum world environment `vacuum_env` based on `random.seed(42)`, but also environments with different Dirt placements as long as the agent starts in `(0,0)`. For example, it should be able to solve `vacuum_env_alternative` below.\n",
    "       \n",
    "The agent also keeps track of the performance measure `performance` as follows:\n",
    "   - For each action among `'Left'`, `'Right'`, `'Up'` and `'Down'`, this value is reduced by -1 (even if the agent does not move). \n",
    "   - If a tile is successfully cleaned by the action `'Suck'`, the value is increased by +10.\n",
    "   - If the action `'Suck'` is used for a clean tile, the value is reduced by -1.\n",
    "   - If the action `'NoOp'`, the performance measure does not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e6bd3",
   "metadata": {},
   "source": [
    "#### Hints:\n",
    "  - To do this task, you can inspect the function `ModelBasedReflexAgentProgram` in `vacuumworld.py` and complete the code of its function `program` with input `percept`.\n",
    "  - When designing the rules for the reflex agent, it is convenient to use the method `is_inbounds(location)` of the `LargeGraphicVacuumEnviornment` (inherited from `XYEnvironment`) to check whether a certain tile location is still within the vacuum world. This method returns `True` if `location` is still within the world, and `False` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10a4e4",
   "metadata": {},
   "source": [
    "The following line is used in the initialization of `LargeGraphicVacuumEnviornment` to set the properties `'Clean'` or `'Dirty'` for each of the 10 locations at random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfed597",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "Once you have implemented the agent program described above, **execute the following cells to show that the agent actually satisfies the requirements.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vacuum_env.agents):\n",
    "    for i in range(len(vacuum_env.agents)):\n",
    "        vacuum_env.delete_thing(vacuum_env.agents[0])\n",
    "model_based_reflex_agent = ModelBasedReflexVacuumAgent(vacuum_env) # initialize the vacuum agent object\n",
    "start_location = (0,0)\n",
    "vacuum_env.add_thing(model_based_reflex_agent,location=start_location) # place the agent onto the vacuum world at location 'start_location' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63269eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.reveal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43728982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all key-value pairs of vacuum world environment:\n",
    "vacuum_env.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7276e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print list of 'things' currently present in the environment:\n",
    "print(vacuum_env.things)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0af03",
   "metadata": {},
   "source": [
    "We can now run the reflex agent for a given number of time steps, and look at how the envrionment changes due to the agent's actions over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 30 # number of time steps\n",
    "delay = 1 # delay in seconds for visualization after each step. Can be reduced to accelerate visualization of agent's moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.run(steps=max_steps,delay=delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b80d8c",
   "metadata": {},
   "source": [
    "We observe the final state of the environment at termination of the agent program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9961572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env.reveal()\n",
    "print(\"Total number of steps taken before termination:\",model_based_reflex_agent.steps)\n",
    "print(\"Last action executed: '\"+model_based_reflex_agent.program.action+\"'\")\n",
    "print(\"Performance measure: \",model_based_reflex_agent.performance)\n",
    "print(\"ModelReflexVacuumAgent is located at {}.\".format(model_based_reflex_agent.location))\n",
    "print(\"State of the Environment: {}.\".format(vacuum_env.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of dirty tiles in environment:\",sum([isinstance(x,Dirt) for x in vacuum_env.things]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b6741",
   "metadata": {},
   "source": [
    "We now test if the agent is also able to solve a world where the Dirt tiles are located slightly differently. <br>\n",
    "**Make sure that the output of the following cells confirms that the model-based reflex agent successfully solves the new problem as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "status_alternative = dict(zip(locs,random.choices(['Clean', 'Dirty'],k=len(locs))))\n",
    "status_alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b10b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env_alternative = VacuumEnvironment(locs=locs,status=status_alternative,color={'Agent': (0,0,0), 'Dirt': (200, 0, 0)})\n",
    "vacuum_env_alternative.reveal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04346243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_based_reflex_agent_alt = ModelBasedReflexVacuumAgent(vacuum_env) # initialize the vacuum agent object\n",
    "if len(vacuum_env.agents):\n",
    "    for i in range(len(vacuum_env_alternative.agents)):\n",
    "        vacuum_env_alternative.delete_thing(vacuum_env_alternative.agents[0])\n",
    "vacuum_env_alternative.add_thing(model_based_reflex_agent_alt,location=start_location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 30 # number of time steps\n",
    "delay = 1 # delay in seconds for visualization after each step. Can be reduced to accelerate visualization of agent's moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81151cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env_alternative.run(steps=max_steps,delay=delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_env_alternative.reveal()\n",
    "print(\"Total number of steps taken before termination:\",model_based_reflex_agent_alt.steps)\n",
    "print(\"Last action executed: '\"+model_based_reflex_agent_alt.program.action+\"'\")\n",
    "print(\"Performance measure: \",model_based_reflex_agent_alt.performance)\n",
    "print(\"ModelReflexVacuumAgent is located at {}.\".format(model_based_reflex_agent_alt.location))\n",
    "print(\"State of the Environment: {}.\".format(vacuum_env_alternative.status))\n",
    "print(\"Number of dirty tiles in environment:\",sum([isinstance(x,Dirt) for x in vacuum_env_alternative.things]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf1281",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid gray\">\n",
    "\n",
    "## Problem 2: Limitations of model-based reflex agents\n",
    "\n",
    "We learning in Problem 1 above how to create a model-based reflex agent that is able to clean all tiles of a world without revisiting any tile.\n",
    "\n",
    "Is it possible to design a vacuum world for which the previously successful model-based reflex agent from Problem 1 _does not_ succeed, e.g., by terminating without cleaning all the tiles?\n",
    "\n",
    "If yes, **design such a vacuum world environment** (of the same dimensions) and **showcase the failure** of the agent of Problem 1. Provide a printout and visualization of the status of environment (analogous to those in Problem 1) after termination. <br>\n",
    "If no, **provide an explanation** of **why** your model-based reflex agent universally solves the problem.\n",
    "\n",
    "Hint: You may experiment with different random seeds for the placement of the Dirt tiles as well as with different initial agent locations `start_location`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add your lines of code below / explanations below ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cbdb4",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid gray\">\n",
    "\n",
    "## Problem 3 (BONUS): A model-based reflex agent that always \"works\"\n",
    "\n",
    "For this problem, **design a model-based reflex agent** that works for\n",
    " - for different vacuum world geometries as long as they rectangular (i.e., for varying `nr_rows` and `nr_cols`, see above) as well as\n",
    " - for different start locations of the agent.\n",
    " \n",
    "This \"more flexible\" agent is now **allowed** to revisit already visited tiles, but only if there is no other option available. In particular, in the case that all adjacent tiles have already been visited, it shall **move along the shortest possible trajectory** to (one of) the closes tiles that have not been visited so far.\n",
    " \n",
    "To this end, complete the function `FlexibleModelBasedReflexVacuumAgent` by adapting the code of `ModelBasedReflexVacuumAgent` accordingly.\n",
    "\n",
    "Provide evidence that it works for the following setups:\n",
    "  - Environment of size `nr_rows=3` and `nr_cols=7`, `start_location=(0,1)`,\n",
    "  - Environment of size `nr_rows=6` and `nr_cols=4`, `start_location=(1,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add your lines of code below ###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
